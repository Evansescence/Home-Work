{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-64-c3e917a97c20>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-c3e917a97c20>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    Congratulations! You've decided to treat yourself to a long holiday vacation in Honolulu, Hawaii! To help with your trip planning, you need to do some climate analysis on the area. The following outlines what you need to do.\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Surfs Up!\n",
    "\n",
    "![surfs-up.jpeg](Images/surfs-up.jpeg)\n",
    "\n",
    "Congratulations! You've decided to treat yourself to a long holiday vacation in Honolulu, Hawaii! To help with your trip planning, you need to do some climate analysis on the area. The following outlines what you need to do.\n",
    "\n",
    "## Step 1 - Climate Analysis and Exploration\n",
    "\n",
    "To begin, use Python and SQLAlchemy to do basic climate analysis and data exploration of your climate database. All of the following analysis should be completed using SQLAlchemy ORM queries, Pandas, and Matplotlib.\n",
    "\n",
    "* Use the provided [starter notebook](climate_starter.ipynb) and [hawaii.sqlite](Resources/hawaii.sqlite) files to complete your climate analysis and data exploration.\n",
    "\n",
    "* Choose a start date and end date for your trip. Make sure that your vacation range is approximately 3-15 days total.\n",
    "\n",
    "* Use SQLAlchemy `create_engine` to connect to your sqlite database.\n",
    "\n",
    "* Use SQLAlchemy `automap_base()` to reflect your tables into classes and save a reference to those classes called `Station` and `Measurement`.\n",
    "\n",
    "### Precipitation Analysis\n",
    "\n",
    "* Design a query to retrieve the last 12 months of precipitation data prior to your trip's start date.\n",
    "\n",
    "* Select only the `date` and `prcp` values.\n",
    "\n",
    "* Load the query results into a Pandas DataFrame and set the index to the date column.\n",
    "\n",
    "* Sort the DataFrame values by `date`.\n",
    "\n",
    "* Plot the results using the DataFrame `plot` method.\n",
    "\n",
    "  ![precipitation](Images/precipitation.png)\n",
    "\n",
    "* Use Pandas to print the summary statistics for the precipitation data.\n",
    "\n",
    "### Station Analysis\n",
    "\n",
    "* Design a query to calculate the total number of stations.\n",
    "\n",
    "* Design a query to find the most active stations.\n",
    "\n",
    "  * List the stations and observation counts in descending order.\n",
    "\n",
    "  * Which station has the highest number of observations?\n",
    "\n",
    "  * Hint: You may need to use functions such as `func.min`, `func.max`, `func.avg`, and `func.count` in your queries.\n",
    "\n",
    "* Design a query to retrieve the last 12 months of temperature observation data (tobs) prior to your trip's start date.\n",
    "\n",
    "  * Filter by the station with the highest number of observations.\n",
    "\n",
    "  * Plot the results as a histogram with `bins=12`.\n",
    "\n",
    "    ![station-histogram](Images/station-histogram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Query' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-d64ad54e76a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_twelve_months\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_twelve_months\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Usage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Programming language usage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Query' has no len()"
     ]
    }
   ],
   "source": [
    "# Design a query to retrieve the last 12 months of precipitation data prior to your \n",
    "#trips start date and plot the results\n",
    "last_twelve_months = session.query(Measurement).\\\n",
    "    filter(Measurement.date < \"10-6-2018\").\\\n",
    "    filter(Measurement.date > \"10-6-2017\").\\\n",
    "    order_by(Measurement.date)\n",
    "\n",
    "x = last_twelve_months\n",
    "y = last_twelve_months\n",
    "plt.xticks(y, len(x))\n",
    "plt.ylabel('Usage')\n",
    "plt.title('Programming language usage')\n",
    " \n",
    "plt.show()\n",
    "#figure out what is actually in csv's.\n",
    "df = pd.read_csv(\"hawaii_measurements.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>prcp</th>\n",
       "      <th>tobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-27</td>\n",
       "      <td>0.12</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>0.03</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>USC00519397</td>\n",
       "      <td>2010-02-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19520</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>0.84</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19521</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-07-25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19522</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19523</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-07-27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19525</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19526</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19527</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19528</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19529</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19530</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19531</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19533</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19534</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19535</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19536</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19537</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19538</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19539</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19540</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>0.22</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19541</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>0.42</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19542</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>0.42</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19543</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19544</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19545</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>0.09</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19546</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19547</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>0.56</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19548</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>0.50</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19549</th>\n",
       "      <td>USC00516128</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>0.45</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19550 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           station        date  prcp  tobs\n",
       "0      USC00519397  2010-01-01  0.08    65\n",
       "1      USC00519397  2010-01-02  0.00    63\n",
       "2      USC00519397  2010-01-03  0.00    74\n",
       "3      USC00519397  2010-01-04  0.00    76\n",
       "4      USC00519397  2010-01-06   NaN    73\n",
       "5      USC00519397  2010-01-07  0.06    70\n",
       "6      USC00519397  2010-01-08  0.00    64\n",
       "7      USC00519397  2010-01-09  0.00    68\n",
       "8      USC00519397  2010-01-10  0.00    73\n",
       "9      USC00519397  2010-01-11  0.01    64\n",
       "10     USC00519397  2010-01-12  0.00    61\n",
       "11     USC00519397  2010-01-14  0.00    66\n",
       "12     USC00519397  2010-01-15  0.00    65\n",
       "13     USC00519397  2010-01-16  0.00    68\n",
       "14     USC00519397  2010-01-17  0.00    64\n",
       "15     USC00519397  2010-01-18  0.00    72\n",
       "16     USC00519397  2010-01-19  0.00    66\n",
       "17     USC00519397  2010-01-20  0.00    66\n",
       "18     USC00519397  2010-01-21  0.00    69\n",
       "19     USC00519397  2010-01-22  0.00    67\n",
       "20     USC00519397  2010-01-23  0.00    67\n",
       "21     USC00519397  2010-01-24  0.01    71\n",
       "22     USC00519397  2010-01-25  0.00    67\n",
       "23     USC00519397  2010-01-26  0.04    76\n",
       "24     USC00519397  2010-01-27  0.12    68\n",
       "25     USC00519397  2010-01-28  0.00    72\n",
       "26     USC00519397  2010-01-30   NaN    70\n",
       "27     USC00519397  2010-01-31  0.03    67\n",
       "28     USC00519397  2010-02-01  0.01    66\n",
       "29     USC00519397  2010-02-03   NaN    67\n",
       "...            ...         ...   ...   ...\n",
       "19520  USC00516128  2017-07-24  0.84    77\n",
       "19521  USC00516128  2017-07-25  0.30    79\n",
       "19522  USC00516128  2017-07-26  0.30    73\n",
       "19523  USC00516128  2017-07-27  0.00    75\n",
       "19524  USC00516128  2017-07-28  0.40    73\n",
       "19525  USC00516128  2017-07-29  0.30    77\n",
       "19526  USC00516128  2017-07-30  0.30    79\n",
       "19527  USC00516128  2017-07-31  0.00    74\n",
       "19528  USC00516128  2017-08-01   NaN    72\n",
       "19529  USC00516128  2017-08-02  0.25    80\n",
       "19530  USC00516128  2017-08-03  0.06    76\n",
       "19531  USC00516128  2017-08-05   NaN    77\n",
       "19532  USC00516128  2017-08-06   NaN    79\n",
       "19533  USC00516128  2017-08-07  0.05    78\n",
       "19534  USC00516128  2017-08-08  0.34    74\n",
       "19535  USC00516128  2017-08-09  0.15    71\n",
       "19536  USC00516128  2017-08-10  0.07    75\n",
       "19537  USC00516128  2017-08-11   NaN    72\n",
       "19538  USC00516128  2017-08-12  0.14    74\n",
       "19539  USC00516128  2017-08-13   NaN    80\n",
       "19540  USC00516128  2017-08-14  0.22    79\n",
       "19541  USC00516128  2017-08-15  0.42    70\n",
       "19542  USC00516128  2017-08-16  0.42    71\n",
       "19543  USC00516128  2017-08-17  0.13    72\n",
       "19544  USC00516128  2017-08-18   NaN    76\n",
       "19545  USC00516128  2017-08-19  0.09    71\n",
       "19546  USC00516128  2017-08-20   NaN    78\n",
       "19547  USC00516128  2017-08-21  0.56    76\n",
       "19548  USC00516128  2017-08-22  0.50    76\n",
       "19549  USC00516128  2017-08-23  0.45    76\n",
       "\n",
       "[19550 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figure out what is actually in csv's.\n",
    "df = pd.read_csv(\"Resources/hawaii_measurements.csv\")\n",
    "df2 = pd.read_csv(\"Resources/hawaii_stations.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "SQL expression, column, or mapped entity expected - got '0        2010-01-01\n1        2010-01-02\n2        2010-01-03\n3        2010-01-04\n4        2010-01-06\n5        2010-01-07\n6        2010-01-08\n7        2010-01-09\n8        2010-01-10\n9        2010-01-11\n10       2010-01-12\n11       2010-01-14\n12       2010-01-15\n13       2010-01-16\n14       2010-01-17\n15       2010-01-18\n16       2010-01-19\n17       2010-01-20\n18       2010-01-21\n19       2010-01-22\n20       2010-01-23\n21       2010-01-24\n22       2010-01-25\n23       2010-01-26\n24       2010-01-27\n25       2010-01-28\n26       2010-01-30\n27       2010-01-31\n28       2010-02-01\n29       2010-02-03\n            ...    \n19520    2017-07-24\n19521    2017-07-25\n19522    2017-07-26\n19523    2017-07-27\n19524    2017-07-28\n19525    2017-07-29\n19526    2017-07-30\n19527    2017-07-31\n19528    2017-08-01\n19529    2017-08-02\n19530    2017-08-03\n19531    2017-08-05\n19532    2017-08-06\n19533    2017-08-07\n19534    2017-08-08\n19535    2017-08-09\n19536    2017-08-10\n19537    2017-08-11\n19538    2017-08-12\n19539    2017-08-13\n19540    2017-08-14\n19541    2017-08-15\n19542    2017-08-16\n19543    2017-08-17\n19544    2017-08-18\n19545    2017-08-19\n19546    2017-08-20\n19547    2017-08-21\n19548    2017-08-22\n19549    2017-08-23\nName: date, Length: 19550, dtype: object'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-20d5efc17353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Perform a query to retrieve the date and prcp values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mValues_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mValues_prcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Save the query results as a Pandas DataFrame and set the index to the date column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/session.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, *entities, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m         :class:`.Session`.\"\"\"\n\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, entities, session)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_polymorphic_adapters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_wrapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m_set_entities\u001b[0;34m(self, entities, entity_wrapper)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_mapper_entities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mentity_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_entity_selectables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, query, column, namespace)\u001b[0m\n\u001b[1;32m   4046\u001b[0m             raise sa_exc.InvalidRequestError(\n\u001b[1;32m   4047\u001b[0m                 \u001b[0;34m\"SQL expression, column, or mapped entity \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4048\u001b[0;31m                 \u001b[0;34m\"expected - got '%r'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4049\u001b[0m             )\n\u001b[1;32m   4050\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_column\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: SQL expression, column, or mapped entity expected - got '0        2010-01-01\n1        2010-01-02\n2        2010-01-03\n3        2010-01-04\n4        2010-01-06\n5        2010-01-07\n6        2010-01-08\n7        2010-01-09\n8        2010-01-10\n9        2010-01-11\n10       2010-01-12\n11       2010-01-14\n12       2010-01-15\n13       2010-01-16\n14       2010-01-17\n15       2010-01-18\n16       2010-01-19\n17       2010-01-20\n18       2010-01-21\n19       2010-01-22\n20       2010-01-23\n21       2010-01-24\n22       2010-01-25\n23       2010-01-26\n24       2010-01-27\n25       2010-01-28\n26       2010-01-30\n27       2010-01-31\n28       2010-02-01\n29       2010-02-03\n            ...    \n19520    2017-07-24\n19521    2017-07-25\n19522    2017-07-26\n19523    2017-07-27\n19524    2017-07-28\n19525    2017-07-29\n19526    2017-07-30\n19527    2017-07-31\n19528    2017-08-01\n19529    2017-08-02\n19530    2017-08-03\n19531    2017-08-05\n19532    2017-08-06\n19533    2017-08-07\n19534    2017-08-08\n19535    2017-08-09\n19536    2017-08-10\n19537    2017-08-11\n19538    2017-08-12\n19539    2017-08-13\n19540    2017-08-14\n19541    2017-08-15\n19542    2017-08-16\n19543    2017-08-17\n19544    2017-08-18\n19545    2017-08-19\n19546    2017-08-20\n19547    2017-08-21\n19548    2017-08-22\n19549    2017-08-23\nName: date, Length: 19550, dtype: object'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform a query to retrieve the date and prcp values\n",
    "Values_date = session.query(df.date)\n",
    "Values_prcp = session.query(df.prcp)\n",
    "# Save the query results as a Pandas DataFrame and set the index to the date column\n",
    "DataFrame = [[],\"date\"]\n",
    "\n",
    "# Sort the dataframe by date\n",
    "sort_by_date = ascending\n",
    "# Use Pandas Plotting with Matplotlib to plot the data\n",
    "\n",
    "# Rotate the xticks for the dates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18103.000000\n",
       "mean         0.160644\n",
       "std          0.468746\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.010000\n",
       "75%          0.110000\n",
       "max         11.530000\n",
       "Name: prcp, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n",
    "df[\"prcp\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19550"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many stations are available in this dataset?\n",
    "df[\"station\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USC00519281    2772\n",
       "USC00519397    2724\n",
       "USC00513117    2709\n",
       "USC00519523    2669\n",
       "USC00516128    2612\n",
       "USC00514830    2202\n",
       "USC00511918    1979\n",
       "USC00517948    1372\n",
       "USC00518838     511\n",
       "Name: station, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the most active stations?\n",
    "# List the stations and the counts in descending order.\n",
    "df[\"station\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station    USC00511918\n",
      "tobs                53\n",
      "dtype: object\n",
      "station    USC00519523\n",
      "tobs                87\n",
      "dtype: object\n",
      "tobs    73.097954\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature most active station?\n",
    "lowest = df[[\"station\",\"tobs\"]].min()\n",
    "print(lowest)\n",
    "highest = df[[\"station\",\"tobs\"]].max()\n",
    "print(highest)\n",
    "average = df[[\"station\",\"tobs\"]].mean()\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data previous to your \n",
    "# trips start date for this station and plot the results as a histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function called `calc_temps` that will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
